"use strict";
/*
 * Copyright (c) 2019, salesforce.com, inc.
 * All rights reserved.
 * SPDX-License-Identifier: MIT
 * For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/MIT
 */
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.runBest = runBest;
const path_1 = __importDefault(require("path"));
const micromatch_1 = __importDefault(require("micromatch"));
const fast_glob_1 = __importDefault(require("fast-glob"));
const builder_1 = require("@best/builder");
const runner_1 = require("@best/runner");
const console_stream_1 = require("@best/console-stream");
const store_1 = require("@best/store");
const api_db_1 = require("@best/api-db");
const analyzer_1 = require("@best/analyzer");
async function getBenchmarkPaths(config) {
    const { testMatch, testPathIgnorePatterns, rootDir: cwd } = config;
    const ignore = [...testPathIgnorePatterns];
    const results = await (0, fast_glob_1.default)(testMatch, { onlyFiles: true, ignore, cwd });
    return results.map((benchPath) => path_1.default.resolve(cwd, benchPath));
}
function filterBenchmarks(matches, filters) {
    if (!filters || !filters.length) {
        return matches;
    }
    // We are doing a OR with the filters (we return the sum of them matches)
    const filteredMatches = filters.reduce((reducer, filter) => {
        let newMatches;
        if (filter.includes('*')) {
            newMatches = (0, micromatch_1.default)(matches, filter);
        }
        else {
            newMatches = matches.filter((match) => match.includes(filter));
        }
        return [...reducer, ...newMatches];
    }, []);
    // Dedupe results (not the most efficient, but the most idiomatic)
    return Array.from(new Set(filteredMatches));
}
function validateBenchmarkNames(matches) {
    matches.reduce((visited, p) => {
        const filename = path_1.default.basename(p);
        if (visited.has(p)) {
            throw new Error(`Duplicated benchmark filename "${filename}". All benchmark file names must be unique.`);
        }
        return visited.add(filename);
    }, new Set());
}
async function getBenchmarkTests(projectConfigs, globalConfig) {
    return Promise.all(projectConfigs.map(async (projectConfig) => {
        const allBenchmarks = await getBenchmarkPaths(projectConfig);
        const filteredBenchmarks = filterBenchmarks(allBenchmarks, globalConfig.nonFlagArgs);
        validateBenchmarkNames(filteredBenchmarks);
        return { config: projectConfig, matches: filteredBenchmarks };
    }));
}
async function buildBundleBenchmarks(benchmarksTests, globalConfig, messager) {
    const benchmarkBuilds = [];
    // We wait for each project to run before starting the next batch
    for (const benchmarkTest of benchmarksTests) {
        const { matches, config } = benchmarkTest;
        const result = await (0, builder_1.buildBenchmarks)(matches, config, globalConfig, messager);
        benchmarkBuilds.push({
            projectName: config.projectName,
            projectConfig: config,
            globalConfig,
            benchmarkBuilds: result,
        });
    }
    return benchmarkBuilds;
}
function hasMatches(benchmarksTests) {
    return benchmarksTests.some(({ matches }) => matches.length);
}
async function runBest(globalConfig, configs, outputStream) {
    const benchmarksTests = await getBenchmarkTests(configs, globalConfig);
    if (!hasMatches(benchmarksTests)) {
        outputStream.write('No benchmark matches found. \n');
        return [];
    }
    let benchmarksBuilds;
    const buildLogStream = new console_stream_1.BuildOutputStream(benchmarksTests, outputStream, globalConfig.isInteractive);
    try {
        buildLogStream.init();
        benchmarksBuilds = await buildBundleBenchmarks(benchmarksTests, globalConfig, buildLogStream);
    }
    finally {
        buildLogStream.finish();
    }
    let benchmarkBundleResults;
    const runnerLogStream = new console_stream_1.RunnerOutputStream(benchmarksBuilds, outputStream, globalConfig.isInteractive);
    try {
        runnerLogStream.init();
        benchmarkBundleResults = await (0, runner_1.runBenchmarks)(benchmarksBuilds, runnerLogStream);
    }
    finally {
        runnerLogStream.finish();
    }
    await (0, analyzer_1.analyzeBenchmarks)(benchmarkBundleResults);
    await (0, store_1.storeBenchmarkResults)(benchmarkBundleResults, globalConfig);
    await (0, api_db_1.saveBenchmarkSummaryInDB)(benchmarkBundleResults, globalConfig);
    return benchmarkBundleResults;
}
//# sourceMappingURL=run_best.js.map